{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa618761-d372-4ca7-993f-6ab05a2c6800",
      "metadata": {
        "id": "fa618761-d372-4ca7-993f-6ab05a2c6800"
      },
      "source": [
        "# NSE Stocks Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing dependencies"
      ],
      "metadata": {
        "id": "LBWpwAKu7Nay"
      },
      "id": "LBWpwAKu7Nay"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0xNBOaZGOE5",
        "outputId": "1086579f-1cb0-473a-a41d-84784d5af93a"
      },
      "id": "U0xNBOaZGOE5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.18)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.7)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (40.0.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (3.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085a801f-106d-48f4-b397-426cb1241b9c",
      "metadata": {
        "id": "085a801f-106d-48f4-b397-426cb1241b9c"
      },
      "source": [
        "## Importting Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30fca589-7a08-4cc3-9c76-da199b11ed46",
      "metadata": {
        "id": "30fca589-7a08-4cc3-9c76-da199b11ed46"
      },
      "outputs": [],
      "source": [
        "# Importing PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Importing Yahoo Finance libraries\n",
        "import yfinance as yf\n",
        "\n",
        "# Importing Python libraries\n",
        "import pandas as pd\n",
        "from pandas_datareader import data as pdr\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Importing SciPy libraries\n",
        "from scipy.special import softmax\n",
        "from scipy.signal import savgol_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e335e0-8577-4986-98ef-fd57511593a7",
      "metadata": {
        "id": "23e335e0-8577-4986-98ef-fd57511593a7"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Stock List"
      ],
      "metadata": {
        "id": "6lqOz0VcBZau"
      },
      "id": "6lqOz0VcBZau"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "782cedbd-245f-45ae-8c38-a9228507d37b",
      "metadata": {
        "id": "782cedbd-245f-45ae-8c38-a9228507d37b"
      },
      "outputs": [],
      "source": [
        "# Importing Stock List from csv to a dataframe\n",
        "\n",
        "CSV_URL = \"https://raw.githubusercontent.com/chaitanya-rane/NSE_stocks_prediction/main/stock_list_short.csv\"\n",
        "stock_list = pd.read_csv(CSV_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4948a45c-dbac-412f-8899-df6a523cb011",
      "metadata": {
        "id": "4948a45c-dbac-412f-8899-df6a523cb011"
      },
      "outputs": [],
      "source": [
        "# Overriding Pandas Dataframe\n",
        "yf.pdr_override()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get stock data"
      ],
      "metadata": {
        "id": "MWVpxI_EBfIs"
      },
      "id": "MWVpxI_EBfIs"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5f73bcc2-181f-417e-a254-6aaea9b6bd8f",
      "metadata": {
        "id": "5f73bcc2-181f-417e-a254-6aaea9b6bd8f"
      },
      "outputs": [],
      "source": [
        "# Get stock value data for stock list for the past 40 days\n",
        "def get_stock_data(stock_list, time_stamp, time_delta):\n",
        "    \n",
        "    stock_data_df = pd.DataFrame()\n",
        "    \n",
        "    for stock in stock_list[\"Symbol\"]:\n",
        "        \n",
        "        stock_name = stock + \".NS\"\n",
        "        \n",
        "        # Importing stock values using Yahoo Finance\n",
        "        old_stdout = sys.stdout # backup current stdout\n",
        "        sys.stdout = open(os.devnull, \"w\")\n",
        "\n",
        "        stock_data = pdr.get_data_yahoo(stock_name, start = time_stamp - timedelta(days=time_delta), end = time_stamp)\n",
        "\n",
        "        sys.stdout = old_stdout # reset old stdout\n",
        "        \n",
        "        stock_data = stock_data.head(40).reset_index()\n",
        "        stock_data_close = stock_data[\"Close\"].squeeze()\n",
        "        \n",
        "        # Adding stock data to stock data dataframe\n",
        "        stock_data_df[stock] = stock_data_close\n",
        "        \n",
        "    return stock_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split data into training and prediction parts"
      ],
      "metadata": {
        "id": "ndEt-c9HBkKQ"
      },
      "id": "ndEt-c9HBkKQ"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f32b4ebe-c93e-4dcd-9857-a681fa28e70b",
      "metadata": {
        "id": "f32b4ebe-c93e-4dcd-9857-a681fa28e70b"
      },
      "outputs": [],
      "source": [
        "# Splitting stock data into training data and prediction data\n",
        "def split_data(stock_data_df):\n",
        "    \n",
        "    train_data = pd.DataFrame(index = range(0,30), columns = stock_data_df.columns)\n",
        "    prediction_data = pd.DataFrame(index = range(0,10), columns = stock_data_df.columns)\n",
        "    \n",
        "    # Reversing the order of rows\n",
        "    stock_data_df = stock_data_df.iloc[::-1]\n",
        "    \n",
        "    # Splitting training and predictions data\n",
        "    for column in stock_data_df.columns:\n",
        "        \n",
        "        train_data[column] = stock_data_df[column].head(30).values\n",
        "        prediction_data[column] = stock_data_df[column][30:40].values\n",
        "    \n",
        "    return train_data, prediction_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get derivatives for train data"
      ],
      "metadata": {
        "id": "_m-Pl3g7BvBZ"
      },
      "id": "_m-Pl3g7BvBZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_derivates(train_data):\n",
        "\n",
        "  for column in train_data.columns:\n",
        "    \n",
        "    # Normalising stock values\n",
        "    train_data[column] = [value/train_data[column].max() for value in train_data[column]]\n",
        "\n",
        "    # Filtering and generating derivatives\n",
        "    filtered_data = savgol_filter(train_data[column], window_length = 3, polyorder = 1, deriv = 1)\n",
        "    train_data[column] = filtered_data\n",
        "\n",
        "  return train_data"
      ],
      "metadata": {
        "id": "UOmd8uR1Hdjp"
      },
      "id": "UOmd8uR1Hdjp",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate prediction labels"
      ],
      "metadata": {
        "id": "Tx7W3EIaB4ZW"
      },
      "id": "Tx7W3EIaB4ZW"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prediction_labels(prediction_data):\n",
        "\n",
        "  growth_data = np.empty(len(prediction_data.columns))\n",
        "  prediction_labels = pd.DataFrame(columns = prediction_data.columns)\n",
        "\n",
        "  for i, column in enumerate(prediction_data.columns):\n",
        "\n",
        "    # Normalise prediction data\n",
        "    prediction_data[column] = [value/prediction_data[column].max() for value in prediction_data[column]]\n",
        "\n",
        "    # Calculate growth\n",
        "    growth = (1 - prediction_data[column][0])/prediction_data[column][0]\n",
        "    growth_data[i] = growth\n",
        "\n",
        "  growth_data = softmax(growth_data)\n",
        "  \n",
        "  for i, column in enumerate(prediction_data.columns):\n",
        "\n",
        "    prediction_labels.at[0, column] = growth_data[i]\n",
        "\n",
        "  return prediction_labels"
      ],
      "metadata": {
        "id": "WVTwYPHUTrlQ"
      },
      "id": "WVTwYPHUTrlQ",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert data to tensors"
      ],
      "metadata": {
        "id": "GDv7PvME7WIw"
      },
      "id": "GDv7PvME7WIw"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensors(train_data, prediction_labels):\n",
        "\n",
        "  # Convert train data to train tensor\n",
        "  train_tensor = torch.tensor(train_data.values)\n",
        "  train_tensor = torch.transpose(train_tensor, 0, 1)\n",
        "\n",
        "  # Convert prediction labels to a labels tensor\n",
        "  label_tensor = torch.empty((1, 10))\n",
        "  for n, col in enumerate(prediction_labels):\n",
        "    label_tensor[0][n] = prediction_labels.at[0,col]\n",
        "\n",
        "  label_tensor = label_tensor.squeeze(dim=0)\n",
        "\n",
        "  return train_tensor, label_tensor"
      ],
      "metadata": {
        "id": "rQ1m5y0WvTTa"
      },
      "id": "rQ1m5y0WvTTa",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build a super function"
      ],
      "metadata": {
        "id": "eiEaU1gQCCXH"
      },
      "id": "eiEaU1gQCCXH"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(stock_list, start_date, end_date):\n",
        "\n",
        "  dates_list = [start_date - timedelta(days = x) for x in range((start_date - end_date).days)]\n",
        "  TIME_DELTA = 100\n",
        "\n",
        "  tensor_size = len(dates_list)\n",
        "\n",
        "  train_tensor_super = torch.empty(tensor_size, 10, 30)\n",
        "  label_tensor_super = torch.empty(tensor_size, 10)\n",
        "\n",
        "  DATA_SPLIT = int(0.8*len(dates_list))\n",
        "\n",
        "  for i, date in enumerate(dates_list):\n",
        "\n",
        "    # Get stock data\n",
        "    stock_data_df = get_stock_data(stock_list, date, TIME_DELTA)\n",
        "\n",
        "    # Split stock data into training and prediction\n",
        "    train_split, prediction_split = split_data(stock_data_df)\n",
        "\n",
        "    # Get derivates for train data\n",
        "    train_split_derivatives = generate_derivates(train_split)\n",
        "\n",
        "    # Generate prediction labels\n",
        "    prediction_split_bools = generate_prediction_labels(prediction_split)\n",
        "\n",
        "    # Convert to Tensors\n",
        "    train_tensor, label_tensor = create_tensors(train_split_derivatives, prediction_split_bools)\n",
        "\n",
        "    # Append to main tensors\n",
        "    train_tensor_super[i] = train_tensor\n",
        "    label_tensor_super[i] = label_tensor\n",
        "\n",
        "    if i%10 == 0:\n",
        "      print(f\"Data prepared for {i+1} days.\")\n",
        "\n",
        "  train_data = train_tensor_super[:DATA_SPLIT]\n",
        "  test_data = train_tensor_super[DATA_SPLIT:]\n",
        "\n",
        "  train_labels = label_tensor_super[:DATA_SPLIT]\n",
        "  test_labels = label_tensor_super[DATA_SPLIT:]\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "eIyZBPqWop8Z"
      },
      "id": "eIyZBPqWop8Z",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_DATE = datetime.strptime(\"2023/05/31\", '%Y/%m/%d')\n",
        "END_DATE = datetime.strptime(\"2023/01/01\", '%Y/%m/%d')\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = generate_data(stock_list, START_DATE, END_DATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGNqM_X5VwP_",
        "outputId": "6cd275fd-95ab-441e-e2d2-c3a8ff588ca9"
      },
      "id": "uGNqM_X5VwP_",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prepared for 1 days.\n",
            "Data prepared for 11 days.\n",
            "Data prepared for 21 days.\n",
            "Data prepared for 31 days.\n",
            "Data prepared for 41 days.\n",
            "Data prepared for 51 days.\n",
            "Data prepared for 61 days.\n",
            "Data prepared for 71 days.\n",
            "Data prepared for 81 days.\n",
            "Data prepared for 91 days.\n",
            "Data prepared for 101 days.\n",
            "Data prepared for 111 days.\n",
            "Data prepared for 121 days.\n",
            "Data prepared for 131 days.\n",
            "Data prepared for 141 days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INy2_NAcWJmz"
      },
      "id": "INy2_NAcWJmz",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLsFBGhUjEoe"
      },
      "id": "uLsFBGhUjEoe",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fU8x9TrKjIff"
      },
      "id": "fU8x9TrKjIff",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dv7r24TqWtkz"
      },
      "id": "dv7r24TqWtkz",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "APVsDf56lKjw"
      },
      "id": "APVsDf56lKjw",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIhqvPMVlqvq"
      },
      "id": "UIhqvPMVlqvq",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9NWXhFNp1AQ"
      },
      "id": "O9NWXhFNp1AQ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgMXFPNmrWNk"
      },
      "id": "LgMXFPNmrWNk",
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}